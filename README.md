# ðŸŽ¥ Video Understanding App (FastAPI + Gradio + pgvector + Gemini)

This project lets you upload a video, analyze it using Google's Gemini LLM, extract semantic highlights, store them in PostgreSQL with `pgvector`, and chat with the content via a Gradio UI.

---

## ðŸš€ Features

- âœ… Upload videos via Gradio
- ðŸ¤– Use Google Gemini to extract semantic video highlights and summaries
- ðŸ§  Save and search LLM-generated highlights using vector similarity (pgvector)
- ðŸ’¬ Chat with video content using semantic search
- ðŸ³ Fully Dockerized setup

---

## ðŸ—‚ï¸ Project Structure

app/  
â”œâ”€â”€ main.py # FastAPI entry  
â”œâ”€â”€ api/  
â”‚ â””â”€â”€ routes.py # API endpoints  
â”‚ â””â”€â”€ schemas.py # Pydantic models  
â”œâ”€â”€ db/  
â”‚ â””â”€â”€ db_manager.py # Postgres + pgvector integration  
â”œâ”€â”€ video_llm/  
â”‚ â””â”€â”€ llm_video_manager.py # Gemini LLM logic  
â”œâ”€â”€ front/  
â”‚ â”œâ”€â”€ front_main.py # Gradio UI with tabs  
â”‚ â”œâ”€â”€ front_db_chat.py # Chat tab  
â”‚ â”œâ”€â”€ front_video_loader.py # Upload tab  
â”œâ”€â”€ video/ # Uploaded videos (volume-mounted)  


---

## ðŸ§° Tech Stack

- ðŸ§¬ **FastAPI** â€” backend API
- ðŸ¤– **Google Generative AI (Gemini)** â€” for LLM-based video understanding and chat
- ðŸ” **pgvector + PostgreSQL** â€” vector storage and search
- ðŸŽ› **Gradio** â€” clean, tabbed frontend
- ðŸ³ **Docker** + `docker-compose` â€” easy deployment

---

## ðŸ§ª How to Run

### 1. Clone the project

```bash
git clone https://github.com/benjika/video-understanding-rag.git
cd video-understanding-rag
```

### 2. Add your .env file:

```bash
GOOGLE_API_KEY=your_google_api_key
POSTGRES_DB=video_understanding_db
POSTGRES_USER=postgres
POSTGRES_PASSWORD=yourpassword
POSTGRES_HOST=db
POSTGRES_PORT=5432
API_URL=http://app:8000/
```

## 3. Build and run with Docker:
```bash
docker-compose up --build
```

Access  
- The app will be available at [http://localhost:8000/gradio/](http://localhost:8000/gradio/)
- The Gradio UI is served at the root path.
> **Note:**  
> On the very first startup, it may take a few minutes for Gradio and the backend to build and initialize. Please be patient while the containers are being prepared.

---

Example Workflow  
1. Upload an .mp4 video via Gradio  
2. Google Gemini extracts highlights + summary  
3. Highlights saved to PostgreSQL using pgvector embeddings  
4. Ask questions like:  
    - "What happened in the beginning?"  
    - "Was there any speech?"  
5. Gradio shows an LLM-generated answer based on similar highlights  

---

## Notes

- Make sure your `GOOGLE_API_KEY` is valid for Gemini LLM.
- The database is persisted in the `pgdata` Docker volume.

---

ðŸ“œ License  
MIT Â© 2025 Benny Katz